{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jabed-Hasan/python/blob/main/Naive_Bayes_Classifier_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Green University of Bangladesh**\n",
        "#**Department of CSE**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## CSE 412: Machine Learning Lab\n",
        "## CLP - 05\n",
        "### Naive Bayes Classifier\n",
        "\n",
        "#####**Student Name:** Farhan Sadik\n",
        "#####**Student ID:** 221002982\n",
        "#####**Instructor:** Md. Jahid Tanvir  \n",
        "#####**Date:** Aug 10, 2025\n"
      ],
      "metadata": {
        "id": "GZ2tU2uhZmBA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPA5x2vO8ZMs",
        "outputId": "939ce9b5-9979-4562-81a5-b3942a3ca9a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data collected: category\n",
            "sport       50\n",
            "politics    50\n",
            "Name: count, dtype: int64\n",
            "  category                                               text\n",
            "0    sport  'World-class potential' - Sesko joins Man Utd ...\n",
            "1    sport  Tavernier rescues 10-man Rangers against Dunde...\n",
            "2    sport  The Hundred: Fire chasing 164 to beat Spirit W...\n",
            "3    sport  Norris and Piastri 'will not properly fall out...\n",
            "4    sport  Watch: England start strongly against France i...\n",
            "Accuracy: 96.67%\n",
            "Confusion Matrix:\n",
            " [[12  1]\n",
            " [ 0 17]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    politics       1.00      0.92      0.96        13\n",
            "       sport       0.94      1.00      0.97        17\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.96      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# ----------------------\n",
        "# Scraper Function\n",
        "# ----------------------\n",
        "def scrape_bbc(category_url, label, max_articles=50):\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "    articles = []\n",
        "\n",
        "    response = requests.get(category_url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Select article links that contain the category keyword\n",
        "    links = soup.select('a[href^=\"/news\"]') if \"politics\" in category_url else soup.select('a[href^=\"/sport\"]')\n",
        "\n",
        "    seen_urls = set()\n",
        "\n",
        "    for link in links:\n",
        "        href = link.get('href')\n",
        "        if not href or href in seen_urls:\n",
        "            continue\n",
        "\n",
        "        # Build full URL if relative\n",
        "        if href.startswith(\"/\"):\n",
        "            article_url = \"https://www.bbc.com\" + href\n",
        "        else:\n",
        "            article_url = href\n",
        "\n",
        "        seen_urls.add(href)\n",
        "\n",
        "        try:\n",
        "            art_resp = requests.get(article_url, headers=headers)\n",
        "            art_soup = BeautifulSoup(art_resp.text, 'html.parser')\n",
        "\n",
        "            # Headline\n",
        "            headline_tag = art_soup.find('h1')\n",
        "            if not headline_tag:\n",
        "                continue\n",
        "            headline = headline_tag.get_text(strip=True)\n",
        "\n",
        "            # Content paragraphs\n",
        "            paragraphs = art_soup.find_all('p')\n",
        "            content = \" \".join([p.get_text(strip=True) for p in paragraphs])\n",
        "\n",
        "            if content and len(content.split()) > 50:  # only keep articles with enough words\n",
        "                articles.append({\"category\": label, \"text\": content})\n",
        "\n",
        "            # Stop if enough articles collected\n",
        "            if len(articles) >= max_articles:\n",
        "                break\n",
        "\n",
        "            time.sleep(1)  # polite delay\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error scraping {article_url}: {e}\")\n",
        "\n",
        "    return articles\n",
        "\n",
        "# ----------------------\n",
        "# Scrape Data\n",
        "# ----------------------\n",
        "sports_data = scrape_bbc(\"https://www.bbc.com/sport\", \"sport\", max_articles=50)\n",
        "politics_data = scrape_bbc(\"https://www.bbc.com/news/politics\", \"politics\", max_articles=50)\n",
        "\n",
        "# Combine and Save\n",
        "df = pd.DataFrame(sports_data + politics_data)\n",
        "df.to_csv(\"news_dataset.csv\", index=False)\n",
        "\n",
        "print(\"Data collected:\", df['category'].value_counts())\n",
        "print(df.head())\n",
        "\n",
        "# ----------------------\n",
        "# Train/Test Split\n",
        "# ----------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['category'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Vectorize Text\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Train Na√Øve Bayes Model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "# ----------------------\n",
        "# Evaluation\n",
        "# ----------------------\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2%}\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred, labels=['politics', 'sport']))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data collected:\", df['category'].value_counts())\n",
        "print(df.head(100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McSAHTwYDioY",
        "outputId": "1ce394c6-46bb-48c4-bc66-653cc6be0416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data collected: category\n",
            "sport       50\n",
            "politics    50\n",
            "Name: count, dtype: int64\n",
            "    category                                               text\n",
            "0      sport  'World-class potential' - Sesko joins Man Utd ...\n",
            "1      sport  Tavernier rescues 10-man Rangers against Dunde...\n",
            "2      sport  The Hundred: Fire chasing 164 to beat Spirit W...\n",
            "3      sport  Norris and Piastri 'will not properly fall out...\n",
            "4      sport  Watch: England start strongly against France i...\n",
            "..       ...                                                ...\n",
            "95  politics  Senior government figures believe they are on ...\n",
            "96  politics  One of the major reasons why Britain's prime m...\n",
            "97  politics  Who is in charge? You might think the answer s...\n",
            "98  politics  \"There's only one relationship that really mat...\n",
            "99  politics  By the time polls closed at 10pm on 4 July 202...\n",
            "\n",
            "[100 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------\n",
        "# User Input Prediction\n",
        "# ----------------------\n",
        "while True:\n",
        "    user_input = input(\"Enter a news headline or article (or type 'exit' to quit): \")\n",
        "    if user_input.lower() == \"exit\":\n",
        "        break\n",
        "\n",
        "    # Convert to vector using the same vocabulary\n",
        "    user_vec = vectorizer.transform([user_input])\n",
        "\n",
        "    # Predict\n",
        "    prediction = model.predict(user_vec)[0]\n",
        "    print(f\"\\nPredicted Category: {prediction}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0S3XPkqEekW",
        "outputId": "6e767139-02e5-4975-c490-3b6d5061197a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a news headline or article (or type 'exit' to quit): The Scourge of ‚ÄòSpot‚ÄëFixing‚Äô Is Coming for American Sports\n",
            "\n",
            "Predicted Category: sport\n",
            "\n",
            "Enter a news headline or article (or type 'exit' to quit): Trump says he will meet Putin in Alaska next Friday\n",
            "\n",
            "Predicted Category: politics\n",
            "\n",
            "Enter a news headline or article (or type 'exit' to quit): exit\n"
          ]
        }
      ]
    }
  ]
}